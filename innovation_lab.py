# -*- coding: utf-8 -*-
"""innovation lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M6jnbv2eT5M728MH2Uv4qJvtbaVWiQy_
"""

import numpy as np
import random
import matplotlib.pyplot as plt
from heapq import heappush, heappop
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# ----------------- Config (tuneable) -----------------
GRID_SIZE = 12
VOCAB = GRID_SIZE * GRID_SIZE
NUM_AGENTS = 3
DATA_SAMPLES = 50000   # adjust for your runtime (was 5000); lower if CPU-only
MAX_EP_LEN = 40
K = 3                   # history length
H = 5                   # prediction horizon (H-step generation)
BATCH = 64
EPOCHS = 200             # fewer if CPU; increase if you want better perf
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
random.seed(123); np.random.seed(123); torch.manual_seed(123)

print("Device:", DEVICE)

# ----------------- Utilities -----------------
def xy_to_token(xy, grid_size=GRID_SIZE):
    x,y = xy
    return int(x*grid_size + y)
def token_to_xy(tok, grid_size=GRID_SIZE):
    return (tok // grid_size, tok % grid_size)
def one_hot_token(tok, vocab=VOCAB):
    vec = np.zeros(vocab, dtype=np.float32)
    vec[tok] = 1.0
    return vec

def neighbors(cell, grid):
    x,y = cell
    for dx,dy in [(-1,0),(1,0),(0,-1),(0,1)]:
        nx,ny = x+dx, y+dy
        if 0 <= nx < grid.shape[0] and 0 <= ny < grid.shape[1] and grid[nx,ny]==0:
            yield (nx,ny)

def heuristic(a,b):
    return abs(a[0]-b[0]) + abs(a[1]-b[1])

def astar_with_avoid(grid, start, goal, avoid_set):
    rows, cols = grid.shape
    open_set = []
    heappush(open_set, (0 + heuristic(start, goal), 0, start, [start]))
    visited = set()
    while open_set:
        _, cost, current, path = heappop(open_set)
        if current in visited:
            continue
        visited.add(current)
        if current == goal:
            return path
        for nb in neighbors(current, grid):
            if nb in avoid_set:
                continue
            new_cost = cost + 1
            heappush(open_set, (new_cost + heuristic(nb, goal), new_cost, nb, path + [nb]))
    return None

# ----------------- Wind & Turbulence helpers -----------------
def gen_wind_field(grid_size=GRID_SIZE, intensity=0.6):
    """
    Generate a wind field: shape (grid_size, grid_size, 2), values in [-intensity, intensity].
    """
    return np.random.uniform(-intensity, intensity, size=(grid_size, grid_size, 2))

def gen_turbulence_mask(grid_size=GRID_SIZE, prob=0.06):
    """
    Binary mask of turbulence cells (1 = turbulence).
    """
    return (np.random.rand(grid_size, grid_size) < prob).astype(int)

# ----------------- Episode generator (with dynamic wind & turbulence) -----------------
def gen_episode_dynamic(grid_size=GRID_SIZE, num_agents=NUM_AGENTS, obstacle_prob=0.12, timesteps=MAX_EP_LEN):
    """
    Produces:
      - static_grid (0/1 obstacles)
      - wind_seq: array[timesteps, grid, grid, 2]
      - turb_seq: array[timesteps, grid, grid] (0/1)
      - starts, goals, trajs (trajectories computed by adaptive planning avoiding turbulence)
    Planning approach:
      For each agent sequentially:
        - Plan adaptively over timesteps: at each t, plan with A* on (static obstacles + turb_seq[t]) and move 1 step, replan next time.
        - Use used_cells reservation so agents avoid each other's planned paths.
    """
    base_grid = (np.random.rand(grid_size, grid_size) < obstacle_prob).astype(int)
    free_cells = [(i,j) for i in range(grid_size) for j in range(grid_size) if base_grid[i,j]==0]
    if len(free_cells) < num_agents*2:
        return None
    choices = random.sample(free_cells, num_agents*2)
    starts = [choices[i] for i in range(num_agents)]
    goals  = [choices[i+num_agents] for i in range(num_agents)]

    # create wind and turbulence sequences
    wind_seq = np.stack([gen_wind_field(grid_size) for _ in range(timesteps)], axis=0)  # [T, G, G, 2]
    turb_seq = np.stack([gen_turbulence_mask(grid_size) for _ in range(timesteps)], axis=0)  # [T, G, G]

    planned_paths = []
    used_cells = set()
    # For each agent, we simulate movement over timesteps using dynamic A* which treats current turbulence as obstacles
    for i in range(num_agents):
        cur = starts[i]
        path = [cur]
        for t in range(timesteps-1):
            # build grid at time t: union of base obstacles and current turbulence mask
            grid_t = np.clip(base_grid + turb_seq[t], 0, 1)
            # plan from current to goal avoiding cells reserved in used_cells (other agents planned cells)
            subpath = astar_with_avoid(grid_t, cur, goals[i], used_cells.copy())
            if subpath is None or len(subpath) < 2:
                # stuck or already at goal -> remain in place
                next_pos = cur
            else:
                # move one step along planned path
                next_pos = subpath[1]
            path.append(next_pos)
            cur = next_pos
            if cur == goals[i]:
                # stay at goal for remaining timesteps
                for tt in range(t+1, timesteps):
                    path.append(cur)
                break
        # ensure path length == timesteps
        if len(path) < timesteps:
            path.extend([path[-1]]*(timesteps - len(path)))
        planned_paths.append(path)
        # reserve the cells used by this agent (conservative)
        used_cells.update(path)
    # verify shapes
    trajs = planned_paths  # list of num_agents lists of length timesteps
    return base_grid, wind_seq, turb_seq, starts, goals, trajs

# Quick test of episode generation sanity
# ep = gen_episode_dynamic()
# print([len(ep[-1][i]) for i in range(NUM_AGENTS)])  # should be MAX_EP_LEN

# ----------------- Build sequence dataset for H-step prediction (includes wind & turb at time t) -----------------
def build_sequence_dataset_dynamic(n_samples=DATA_SAMPLES):
    print("Building sequence dataset with dynamic wind & turbulence (samples ~ {}) ...".format(n_samples))
    Xg, Xw, Xh, Xo, Yseq = [], [], [], [], []
    created = 0
    attempts = 0
    max_attempts = n_samples * 10
    while created < n_samples and attempts < max_attempts:
        attempts += 1
        ep = gen_episode_dynamic()
        if ep is None:
            continue
        base_grid, wind_seq, turb_seq, starts, goals, trajs = ep
        # for each timestep t (we need t in [K, MAX_EP_LEN-H-1]) and each agent, create sample
        for t in range(K, MAX_EP_LEN - H - 1):
            for ag in range(NUM_AGENTS):
                # current wind & turb at time t (flattened): wind_x, wind_y, turb_mask
                wind_t = wind_seq[t]                # shape [G,G,2]
                wind_flat = np.concatenate([wind_t[:,:,0].flatten(), wind_t[:,:,1].flatten(), turb_seq[t].flatten()]).astype(np.float32)
                # static grid flattened
                g_flat = base_grid.flatten().astype(np.float32)
                # history tokens for this agent (last K positions), oldest->latest
                hist_tokens = [xy_to_token(trajs[ag][t - K + 1 + k]) for k in range(K)]
                hist_oh = np.concatenate([one_hot_token(tok) for tok in hist_tokens])
                # other agents current positions (at time t)
                others = []
                for other in range(NUM_AGENTS):
                    if other == ag: continue
                    others.append(one_hot_token(xy_to_token(trajs[other][t])))
                others_concat = np.concatenate(others) if len(others)>0 else np.zeros(VOCAB*(NUM_AGENTS-1), dtype=np.float32)
                # target sequence: tokens at t+1 .. t+H (the agent's next H cells)
                target_seq = [xy_to_token(trajs[ag][t + 1 + h]) for h in range(H)]
                # append
                Xg.append(g_flat); Xw.append(wind_flat); Xh.append(hist_oh); Xo.append(others_concat); Yseq.append(target_seq)
                created += 1
                if created >= n_samples:
                    break
            if created >= n_samples:
                break
    if created == 0:
        raise RuntimeError("Failed to build any dataset samples; try lowering obstacle_prob or increasing max attempts.")
    Xg = np.stack(Xg); Xw = np.stack(Xw); Xh = np.stack(Xh); Xo = np.stack(Xo); Yseq = np.array(Yseq, dtype=np.int64)
    print("Built dataset shapes:", Xg.shape, Xw.shape, Xh.shape, Xo.shape, Yseq.shape)
    return Xg, Xw, Xh, Xo, Yseq

# Build dataset (this will take some time)
Xg, Xw, Xh, Xo, Yseq = build_sequence_dataset_dynamic(DATA_SAMPLES)

# ----------------- Torch dataset & loader (include wind input) -----------------
class SeqAgentDatasetDynamic(Dataset):
    def __init__(self, Xg, Xw, Xh, Xo, Y):
        self.Xg = torch.tensor(Xg, dtype=torch.float32)
        self.Xw = torch.tensor(Xw, dtype=torch.float32)
        self.Xh = torch.tensor(Xh, dtype=torch.float32)
        self.Xo = torch.tensor(Xo, dtype=torch.float32)
        self.Y  = torch.tensor(Y, dtype=torch.long)  # [N, H]
    def __len__(self):
        return self.Xg.shape[0]
    def __getitem__(self, idx):
        return self.Xg[idx], self.Xw[idx], self.Xh[idx], self.Xo[idx], self.Y[idx]

ds = SeqAgentDatasetDynamic(Xg, Xw, Xh, Xo, Yseq)
loader = DataLoader(ds, batch_size=BATCH, shuffle=True, drop_last=True)

# ----------------- Upgraded Autoregressive Transformer (accepts wind+turbo) -----------------
class AutoregrTransformerWind(nn.Module):
    def __init__(self, vocab=VOCAB, hist_dim=VOCAB*K, others_dim=VOCAB*(NUM_AGENTS-1),
                 grid_dim=VOCAB, wind_dim=GRID_SIZE*GRID_SIZE*3, d_model=192, nhead=6, num_layers=3):
        super().__init__()
        self.grid_fc = nn.Linear(grid_dim, d_model)
        self.wind_fc = nn.Linear(wind_dim, d_model)           # new projection for wind+turbulence
        self.hist_fc = nn.Linear(hist_dim, d_model)
        self.others_fc = nn.Linear(others_dim, d_model) if others_dim>0 else nn.Linear(1, d_model)

        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=384, dropout=0.1)
        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        self.token_emb = nn.Embedding(vocab, d_model)
        self.pos_emb = nn.Embedding(60, d_model)

        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=384, dropout=0.1)
        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)

        self.out_fc = nn.Linear(d_model, vocab)

    def encode_src(self, grid, wind, hist, others):
        # project each input and create a source sequence [grid, wind, hist, others]
        g = self.grid_fc(grid).unsqueeze(0)
        w = self.wind_fc(wind).unsqueeze(0)
        h = self.hist_fc(hist).unsqueeze(0)
        o = self.others_fc(others).unsqueeze(0)
        src = torch.cat([g, w, h, o], dim=0)   # seq_len = 4
        memory = self.encoder(src)
        return memory

    def forward(self, grid, wind, hist, others, tgt_tokens=None, teacher_forcing_prob=0.5):
        B = grid.shape[0]
        memory = self.encode_src(grid, wind, hist, others)
        # last history token index
        last_tok_idx = torch.argmax(hist.reshape(B, K, VOCAB)[:, -1, :], dim=-1).to(grid.device)
        dec_input_idxs = last_tok_idx.unsqueeze(1)  # [B,1]

        generated_logits = []
        for step in range(H):
            seq_len = dec_input_idxs.shape[1]
            positions = torch.arange(seq_len, device=grid.device).unsqueeze(0).repeat(B,1)
            tok_emb = self.token_emb(dec_input_idxs) + self.pos_emb(positions)
            tgt = tok_emb.permute(1,0,2)
            tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(grid.device)
            dec_out = self.decoder(tgt, memory, tgt_mask=tgt_mask)
            last_out = dec_out[-1,:,:]
            logits = self.out_fc(last_out)
            generated_logits.append(logits.unsqueeze(1))

            if tgt_tokens is not None:
                use_teacher = (torch.rand(B, device=grid.device) < teacher_forcing_prob)
                next_tok = torch.where(use_teacher, tgt_tokens[:, step], torch.argmax(logits, dim=-1))
            else:
                next_tok = torch.argmax(logits, dim=-1)
            dec_input_idxs = torch.cat([dec_input_idxs, next_tok.unsqueeze(1)], dim=1)

        logits_all = torch.cat(generated_logits, dim=1)  # [B,H,V]
        return logits_all

# ----------------- Initialize model, optimizer, scheduler, loss -----------------
wind_dim = GRID_SIZE * GRID_SIZE * 3
model = AutoregrTransformerWind(wind_dim=wind_dim).to(DEVICE)
opt = optim.AdamW(model.parameters(), lr=1e-3)
scheduler = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)
crit = nn.CrossEntropyLoss()

# ----------------- Training loop with gradual teacher forcing & early stopping -----------------
best_loss = float('inf')
patience = 0
print("Starting training with wind+turbulence awareness (GPU recommended)...")

for ep in range(EPOCHS):
    model.train()
    total_loss = 0.0
    tf_prob = 0.8 - 0.5 * (ep / (max(1, EPOCHS - 1)))  # 0.8 -> ~0.3 schedule
    for g, w, h, o, y in loader:
        g = g.to(DEVICE); w = w.to(DEVICE); h = h.to(DEVICE); o = o.to(DEVICE); y = y.to(DEVICE)
        opt.zero_grad()
        logits = model(g, w, h, o, tgt_tokens=y, teacher_forcing_prob=tf_prob)  # [B,H,V]
        loss = sum(crit(logits[:,t,:], y[:,t]) for t in range(H)) / H
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        opt.step()
        total_loss += loss.item()
    scheduler.step()
    avg_loss = total_loss / len(loader)
    print(f"Epoch {ep+1}/{EPOCHS} | Loss: {avg_loss:.4f} | TF={tf_prob:.2f}")
    if avg_loss < best_loss:
        best_loss = avg_loss
        patience = 0
        torch.save(model.state_dict(), "best_transformer_wind.pt")
    else:
        patience += 1
        if patience >= 3:
            print("Early stopping - no improvement for 3 epochs.")
            break

print("Training finished. Best loss:", best_loss)

# ----------------- Inference helpers: generate H-step for one agent (uses current wind+turbo) -----------------
def generate_h_for_agent_wind(model, grid, wind_flat, hist_tokens, other_positions, device=DEVICE, H=H):
    model.eval()
    g_t = torch.tensor(grid.flatten(), dtype=torch.float32, device=device).unsqueeze(0)
    w_t = torch.tensor(wind_flat, dtype=torch.float32, device=device).unsqueeze(0)
    hist_oh = np.concatenate([one_hot_token(t) for t in hist_tokens])
    h_t = torch.tensor(hist_oh, dtype=torch.float32, device=device).unsqueeze(0)
    others_oh = np.concatenate([one_hot_token(t) for t in other_positions]) if len(other_positions)>0 else np.zeros(VOCAB*(NUM_AGENTS-1), dtype=np.float32)
    o_t = torch.tensor(others_oh, dtype=torch.float32, device=device).unsqueeze(0)
    with torch.no_grad():
        logits_seq = model(g_t, w_t, h_t, o_t, tgt_tokens=None)  # [1,H,V]
        preds = torch.argmax(logits_seq, dim=-1).cpu().numpy().astype(int)[0].tolist()
    return preds

# ----------------- Run episode with H-step predictions (per-agent) using dynamic wind & turb -----------------
def run_episode_horizon_wind(model, base_grid, wind_seq, turb_seq, starts, goals, max_steps=MAX_EP_LEN, H=H):
    cur = list(starts)
    trajs = [[s] for s in starts]
    for t in range(max_steps):
        proposals = []
        # prepare current flat wind+turbo for time t
        wind_t = wind_seq[t]              # [G,G,2]
        wind_flat = np.concatenate([wind_t[:,:,0].flatten(), wind_t[:,:,1].flatten(), turb_seq[t].flatten()]).astype(np.float32)
        for ag in range(len(cur)):
            his = trajs[ag]
            hist_tokens = [xy_to_token(his[max(0, len(his)-K + k)]) for k in range(K)]
            other_pos = [xy_to_token(cur[other]) for other in range(len(cur)) if other!=ag]
            preds = generate_h_for_agent_wind(model, base_grid, wind_flat, hist_tokens, other_pos, device=DEVICE, H=H)
            proposed = token_to_xy(preds[0])
            # validate neighbor
            if proposed not in list(neighbors(cur[ag], base_grid)) and proposed != cur[ag]:
                proposed = cur[ag]
            proposals.append(proposed)
        # resolve collisions
        counts = {}
        for p in proposals: counts[p] = counts.get(p,0)+1
        new_positions = []
        for ag,p in enumerate(proposals):
            if counts[p] > 1:
                new_positions.append(cur[ag])
            else:
                new_positions.append(p)
        cur = new_positions
        for ag in range(len(cur)):
            trajs[ag].append(cur[ag])
    success = [ (tr[-1] == goals[i]) for i,tr in enumerate(trajs) ]
    collision = False
    for t in range(len(trajs[0])):
        pos_t = [tr[t] for tr in trajs]
        if len(pos_t) != len(set(pos_t)):
            collision = True
            break
    return trajs, success, collision

# ----------------- Evaluation across multiple dynamic episodes -----------------
def evaluate_horizon_model_wind(model, n_episodes=40):
    succ_counts = 0
    collisions = 0
    times_to_goal = []
    run_episodes = 0
    for i in range(n_episodes):
        ep = gen_episode_dynamic()
        if ep is None:
            continue
        base_grid, wind_seq, turb_seq, starts, goals, trajs_truth = ep
        run_episodes += 1
        trajs_pred, success, collision = run_episode_horizon_wind(model, base_grid, wind_seq, turb_seq, starts, goals)
        succ_counts += sum(success)
        collisions += 1 if collision else 0
        for ag, s in enumerate(success):
            if s:
                t_first = next((t for t,p in enumerate(trajs_pred[ag]) if p == goals[ag]), None)
                if t_first is not None:
                    times_to_goal.append(t_first)
    total_agents = run_episodes * NUM_AGENTS
    succ_rate = succ_counts / total_agents * 100 if total_agents>0 else 0
    collision_rate = collisions / run_episodes * 100 if run_episodes>0 else 0
    avg_time = np.mean(times_to_goal) if times_to_goal else float('nan')
    print(f"H-step Dynamic Evaluation over {run_episodes} episodes:")
    print(f"  - Agent success rate: {succ_rate:.1f}%")
    print(f"  - Episodes with collision: {collision_rate:.1f}%")
    print(f"  - Avg time-to-goal (succeeded agents): {avg_time:.2f} steps")
    return succ_rate, collision_rate, avg_time

# Try load best weights if available
try:
    model.load_state_dict(torch.load("best_transformer_wind.pt", map_location=DEVICE))
    print("Loaded best saved model weights.")
except Exception as e:
    print("No saved model loaded (continuing with current model).", e)

# Run evaluation and show results
evaluate_horizon_model_wind(model, n_episodes=40)

# ----------------- Visualize example dynamic episode -----------------
ep = None
while ep is None:
    ep = gen_episode_dynamic()
base_grid, wind_seq, turb_seq, starts, goals, trajs_truth = ep
trajs_pred, success, collision = run_episode_horizon_wind(model, base_grid, wind_seq, turb_seq, starts, goals)
fig, ax = plt.subplots(1,1, figsize=(8,8))
# show static obstacles
ax.imshow(base_grid, cmap='gray_r', alpha=0.6)
colors = ['tab:blue','tab:orange','tab:purple','tab:green','tab:red']
for ag in range(NUM_AGENTS):
    gt = trajs_truth[ag][:len(trajs_pred[ag])]
    px, py = zip(*gt)
    ax.plot(py, px, '--', color=colors[ag], alpha=0.5, label=f'Agent{ag} GT')
    pr = trajs_pred[ag]
    qx,qy = zip(*pr)
    ax.plot(qy, qx, '-', color=colors[ag], label=f'Agent{ag} Pred')
    ax.scatter(starts[ag][1], starts[ag][0], marker='D', color=colors[ag])
    ax.scatter(goals[ag][1], goals[ag][0], marker='X', color=colors[ag])
# overlay turbulence at final timestep as red transparent patches (example)
t_show = min(5, MAX_EP_LEN-1)
turb = turb_seq[t_show]
for (i,j), val in np.ndenumerate(turb):
    if val:
        rect = plt.Rectangle((j-0.5, i-0.5), 1,1, color='red', alpha=0.18)
        ax.add_patch(rect)
# overlay wind vectors (sampled)
wind_vis = wind_seq[t_show]
step = max(1, GRID_SIZE // 8)
for i in range(0, GRID_SIZE, step):
    for j in range(0, GRID_SIZE, step):
        u,v = wind_vis[i,j]
        ax.arrow(j, i, v*0.6, u*0.6, head_width=0.15, head_length=0.15, fc='k', ec='k', alpha=0.7)
ax.set_title(f"Dynamic episode (t={t_show}) â€” collision={collision}")
ax.legend()
plt.gca().invert_yaxis()
plt.show()

print("Done. Model weights (if saved): best_transformer_wind.pt")